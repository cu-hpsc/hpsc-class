{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Parallelism\n",
    "\n",
    "* Batch parallelism (e.g., MPI)\n",
    "  * Computation more expensive than data load/store\n",
    "  * Thinking up-front to maximize efficiency\n",
    "  * Scalable and low-latency\n",
    "* Interactive/exploratory analysis\n",
    "  * Don't know the question until seeing data\n",
    "  * Iterative exploration\n",
    "  * Some analyses are cheap, others are expensive\n",
    "  * Data load/store and preprocessing expensive compared to (some) analysis\n",
    "  * Modest scale (single node to perhaps dozens of hundreds of nodes for the right problem)\n",
    "\n",
    "### Example platforms\n",
    "\n",
    "* [Hadoop](https://hadoop.apache.org/)\n",
    "  * Reliable MapReduce system with disk-based storage and replication for fault tolerance\n",
    "  * Java with bindings for other languages\n",
    "* [Spark](https://spark.apache.org/docs/latest/quick-start.html)\n",
    "  * In-memory child of Hadoop\n",
    "  ![](https://spark.apache.org/images/logistic-regression.png)\n",
    "* [Dask](https://dask.org/)\n",
    "  * Python-based platform that integrates with NumPy, SciPy, Pandas, and Scikit-Learn\n",
    "  * Lead developer employed by NVIDIA\n",
    "* [IPyParallel](https://ipyparallel.readthedocs.io/en/latest/)\n",
    "  * Control-worker design\n",
    "  * Can use MPI\n",
    "    * Expressive parallel algorithms\n",
    "    * A bit flaky, especially after error conditions (in my experience)\n",
    "  * [On NERSC's Cori](https://drive.google.com/file/d/1-OFjrk1q3L1d3uakr2xkozrPn2c2VZpZ/view)\n",
    "  ![](ipyparallel-cori.png)\n",
    "* [Parsl-python](http://parsl-project.org/)\n",
    "  * [Slides](https://drive.google.com/file/d/1Yy_jUWLvdSPHsXd4wtsfcIXoGvO2DY9g/view)\n",
    "  ![](parsl-slide.png)\n",
    "\n",
    "* [Workshop: Jupyter for Science User Facilities and High Performance Computing](https://jupyter-workshop-2019.lbl.gov/agenda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask notes\n",
    "\n",
    "Distributed API operations are lazy, returning futures. Computation actually occurs when you ask for `.result()` (gathers result locally) or call `.persist()` to start computing a distributed result.\n",
    "\n",
    "#### Overhead\n",
    "\n",
    "> Partitions should fit comfortably in memory (smaller than a gigabyte) but also not be too many. **Every operation on every partition takes the central scheduler a few hundred microseconds to process.** If you have a few thousand tasks this is barely noticeable, but it is nice to reduce the number if possible.\n",
    "\n",
    "```python\n",
    "df = dd.read_csv('s3://bucket/path/to/*.csv')\n",
    "df = df[df.name == 'Alice']  # only 1/100th of the data\n",
    "df = df.repartition(npartitions=df.npartitions // 100)\n",
    "\n",
    "df = df.persist()  # if on a distributed system\n",
    "```\n",
    "\n",
    "* https://docs.dask.org/en/latest/dataframe-best-practices.html\n",
    "* https://distributed.readthedocs.io/en/latest/limitations.html\n",
    "\n",
    "#### Keeping data distributed\n",
    "\n",
    "https://distributed.readthedocs.io/en/latest/efficiency.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45897</li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.67 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45897' processes=4 threads=4, memory=16.67 GB>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Future: random</b> <font color=\"gray\">status: </font><font color=\"black\">pending</font>, <font color=\"gray\">key: </font>random-4fead107d39a451af48ce8db919b0254"
      ],
      "text/plain": [
       "<Future: pending, key: random-4fead107d39a451af48ce8db919b0254>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = client.submit(np.random.random, (1000, 1000))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Future: random</b> <font color=\"gray\">status: </font><font color=\"black\">finished</font>, <font color=\"gray\">type: </font>numpy.ndarray, <font color=\"gray\">key: </font>random-4fead107d39a451af48ce8db919b0254"
      ],
      "text/plain": [
       "<Future: finished, type: numpy.ndarray, key: random-4fead107d39a451af48ce8db919b0254>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.result().shape # Moves data to control process, then computes shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.submit(lambda a: a.shape, x).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dask/dask-org/master/images/bokeh-task-stream.gif)\n",
    "\n",
    "* https://distributed.readthedocs.io/en/latest/diagnosing-performance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QR factorization\n",
    "\n",
    "* [Direct QR factorizations for tall-and-skinnymatrices in MapReduce architectures](https://arxiv.org/pdf/1301.1071.pdf)\n",
    "\n",
    "### Indirect approach: compute $R$, then $Q = A R^{-1}$\n",
    "\n",
    "$$ R^T R = A^T A $$\n",
    "\n",
    "![](mapreduce-chol-qr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Direct\" Householder $QR = A$\n",
    "\n",
    "Operates one column at a time; inefficient parallel distribution and memory access.\n",
    "\n",
    "![](mapreduce-householder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct TSQR\n",
    "\n",
    "![](mapreduce-tsqr.png)\n",
    "\n",
    "![](mapreduce-figure6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | Value |\n",
    "|------|----------|\n",
    "| Nodes | 10 |\n",
    "| Processor | [i7-960](https://ark.intel.com/content/www/us/en/ark/products/37151/intel-core-i7-960-processor-8m-cache-3-20-ghz-4-80-gt-s-intel-qpi.html) |\n",
    "| Memory/node | 24 GB |\n",
    "| Total memory | 240 GB |\n",
    "| Memory BW/node | 25 GB/s |\n",
    "| Cores/node | 4 |\n",
    "| Clock | 3.2 GHz |\n",
    "| flops/cycle/core | 2 |\n",
    "| GF/s/node | 25.6 |\n",
    "| flops/byte | 1 |\n",
    "\n",
    "![](mapreduce-table2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flops</th>\n",
       "      <th>sec_mem</th>\n",
       "      <th>sec_flops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.000000e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>1.280000e+11</td>\n",
       "      <td>1.280000e+11</td>\n",
       "      <td>1.024</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.500000e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>2.000000e+11</td>\n",
       "      <td>5.000000e+11</td>\n",
       "      <td>1.600</td>\n",
       "      <td>9.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>25</td>\n",
       "      <td>1.200000e+11</td>\n",
       "      <td>7.500000e+11</td>\n",
       "      <td>0.960</td>\n",
       "      <td>14.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000e+08</td>\n",
       "      <td>50</td>\n",
       "      <td>2.000000e+11</td>\n",
       "      <td>2.500000e+12</td>\n",
       "      <td>1.600</td>\n",
       "      <td>48.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.500000e+08</td>\n",
       "      <td>100</td>\n",
       "      <td>1.200000e+11</td>\n",
       "      <td>3.000000e+12</td>\n",
       "      <td>0.960</td>\n",
       "      <td>58.593750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rows  cols         bytes         flops  sec_mem  sec_flops\n",
       "0  4.000000e+09     4  1.280000e+11  1.280000e+11    1.024   2.500000\n",
       "1  2.500000e+09    10  2.000000e+11  5.000000e+11    1.600   9.765625\n",
       "2  6.000000e+08    25  1.200000e+11  7.500000e+11    0.960  14.648438\n",
       "3  5.000000e+08    50  2.000000e+11  2.500000e+12    1.600  48.828125\n",
       "4  1.500000e+08   100  1.200000e+11  3.000000e+12    0.960  58.593750"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(dict(rows=[4e9, 2.5e9, .6e9, .5e9, .15e9], cols=[4,10,25,50,100]))\n",
    "df['bytes'] = 8 * df.rows * df.cols\n",
    "df['flops'] = 2 * df.rows * df.cols**2\n",
    "bandwidth = 125e9  # 50% of peak\n",
    "flops = 256e9 * .2 # 20% of peak\n",
    "df['sec_mem'] = df.bytes / bandwidth\n",
    "df['sec_flops'] = df.flops / flops\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](mapreduce-table6.png)\n",
    "\n",
    "#### Notes\n",
    "* The data always fits in (distributed) memory\n",
    "* Limited by flops for all numbers of columns\n",
    "  * What about on today's computers?\n",
    "* Using disk and the present algorithm is tens to hundreds of times slower than an efficient in-memory algorithm.\n",
    "* The many passes over data in (unblocked) Householder is crippling\n",
    "* Direct TSQR and Cholesky QR with refinement are good algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering)\n",
    "\n",
    "Given $n$ points $x_i$ in $d$-dimensional space, the k-means algorithm finds $K$ clusters by\n",
    "1. Initialize centers $\\{ c_k \\in R^d \\}_{k=1}^K $\n",
    "2. Repeat (Lloyd's algorithm)\n",
    "  * Assign each $x_i$ to the nearest center $c_k$\n",
    "  * Shift each center $c_k$ to the mean (centroid) of its $x_i$\n",
    "  \n",
    "This minimizes the cost function\n",
    "\n",
    "$$ \\phi(\\mathcal C) = \\sum_{x\\in X} \\min_k \\lVert x - c_k \\rVert^2 $$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/e/ea/K-means_convergence.gif)\n",
    "By <a href=\"//commons.wikimedia.org/wiki/User:Chire\" title=\"User:Chire\">Chire</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=59409335\">Link</a>\n",
    "\n",
    "### Initialization matters\n",
    "\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">K-means++ defines a seeding strategy which is approximately optimal up to a logarithmic factor. Running k-means afterward only marginally improves the quantization error (as opposed to bad seeding). <a href=\"https://t.co/L8w45IE9gV\">https://t.co/L8w45IE9gV</a> <a href=\"https://t.co/7DtaTZukTU\">pic.twitter.com/7DtaTZukTU</a></p>&mdash; Gabriel Peyré (@gabrielpeyre) <a href=\"https://twitter.com/gabrielpeyre/status/1194495104855052288?ref_src=twsrc%5Etfw\">November 13, 2019</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n",
    "\n",
    "#### Serial `kmeans++` and parallel `kmeans||`\n",
    "\n",
    "![](kmeans-plusplus.png)\n",
    "![](kmeans-parallel.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
